{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "30b268b9-6775-483a-8935-b5e1e6534be0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For the BERT model (tokenizer,...)\n",
    "from transformers import AutoModel, AutoTokenizer, BertTokenizer\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# For Progress Bars\n",
    "from tqdm import tqdm\n",
    "\n",
    "# For JSON input\n",
    "import json\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f0a948-58d3-46b9-a523-df0ffacfe47c",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "068b19b3-9506-4790-9e9a-b73a79c7e198",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filename': 'airport_1.jpg',\n",
       " 'imgid': 0,\n",
       " 'sentences': [{'tokens': ['many',\n",
       "    'planes',\n",
       "    'are',\n",
       "    'parked',\n",
       "    'next',\n",
       "    'to',\n",
       "    'a',\n",
       "    'long',\n",
       "    'building',\n",
       "    'in',\n",
       "    'an',\n",
       "    'airport'],\n",
       "   'raw': 'many planes are parked next to a long building in an airport .',\n",
       "   'imgid': 0,\n",
       "   'sentid': 0},\n",
       "  {'tokens': ['many',\n",
       "    'planes',\n",
       "    'are',\n",
       "    'parked',\n",
       "    'next',\n",
       "    'to',\n",
       "    'a',\n",
       "    'long',\n",
       "    'building',\n",
       "    'in',\n",
       "    'an',\n",
       "    'airport'],\n",
       "   'raw': 'many planes are parked next to a long building in an airport .',\n",
       "   'imgid': 0,\n",
       "   'sentid': 1},\n",
       "  {'tokens': ['many',\n",
       "    'planes',\n",
       "    'are',\n",
       "    'parked',\n",
       "    'next',\n",
       "    'to',\n",
       "    'a',\n",
       "    'long',\n",
       "    'building',\n",
       "    'in',\n",
       "    'an',\n",
       "    'airport'],\n",
       "   'raw': 'many planes are parked next to a long building in an airport .',\n",
       "   'imgid': 0,\n",
       "   'sentid': 2},\n",
       "  {'tokens': ['many',\n",
       "    'planes',\n",
       "    'are',\n",
       "    'parked',\n",
       "    'next',\n",
       "    'to',\n",
       "    'a',\n",
       "    'long',\n",
       "    'building',\n",
       "    'in',\n",
       "    'an',\n",
       "    'airport'],\n",
       "   'raw': 'many planes are parked next to a long building in an airport .',\n",
       "   'imgid': 0,\n",
       "   'sentid': 3},\n",
       "  {'tokens': ['many',\n",
       "    'planes',\n",
       "    'are',\n",
       "    'parked',\n",
       "    'next',\n",
       "    'to',\n",
       "    'a',\n",
       "    'long',\n",
       "    'building',\n",
       "    'in',\n",
       "    'an',\n",
       "    'airport'],\n",
       "   'raw': 'many planes are parked next to a long building in an airport .',\n",
       "   'imgid': 0,\n",
       "   'sentid': 4}],\n",
       " 'split': 'train',\n",
       " 'sentids': [0, 1, 2, 3, 4]}"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../../Datasets/RSICD/dataset_rsicd.json', 'r') as f:\n",
    "    data = json.load(f)['images']\n",
    "    \n",
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728d377d-3bb5-45a4-bac3-948dedea5bf1",
   "metadata": {},
   "source": [
    "## Tokenize Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "8d68dbff-1c4c-42d0-9e2c-8978d5d1017e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['many planes are parked in an airport near a large parking lot .',\n",
       " 'many planes are parked in an airport .',\n",
       " 'a airport in side while with some square meadow besides .',\n",
       " 'four planes are parked in an airport near several buildings with parking lots .',\n",
       " 'some planes are parked in an airport near a piece of green trees .']"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pretrained BERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('prajjwal1/bert-mini')\n",
    "\n",
    "sentences = []\n",
    "\n",
    "# for elem in data:\n",
    "#     for idx in range(5):\n",
    "#         sentences.append(elem['sentences'][idx]['raw'])\n",
    "\n",
    "for elem in data:\n",
    "    sentences.append(elem['sentences'][0]['raw'])\n",
    "\n",
    "sentences[20:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "6a9f067d-68ea-46e8-9a13-c36cb9dfb6fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10921"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "b710016a-9e2a-4514-8985-3a0bcac24003",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a custom Dataset class\n",
    "class SentenceDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, sentences, tokenizer, max_length=128):\n",
    "        self.sentences = sentences\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.sentences[idx]\n",
    "\n",
    "        # Tokenize the sentence\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            sentence,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            truncation=True,\n",
    "            return_token_type_ids=False,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        inputs['input_ids'] = inputs['input_ids'].squeeze(0)\n",
    "        inputs['attention_mask'] = inputs['attention_mask'].squeeze(0)\n",
    "\n",
    "        return inputs\n",
    "\n",
    "# Create an instance of the custom dataset\n",
    "custom_dataset = SentenceDataset(sentences, tokenizer, max_length=64)\n",
    "\n",
    "# Create a DataLoader for the custom dataset\n",
    "dataloader = DataLoader(custom_dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b658f36b-43d3-43f2-85fd-d7c2fef0445c",
   "metadata": {},
   "source": [
    "## Embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "3082471f-85fc-4076-8231-0815d2dc9594",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cuda_device = 'cuda:0'\n",
    "device = torch.device(cuda_device if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "e4a417ff-6067-4f4a-bd10-90479b27470e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bert = AutoModel.from_pretrained(\"prajjwal1/bert-mini\", output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9a55cf-53db-4dcb-9a1d-bd23ee0a39bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Last Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380b9ee7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting Embeddings (batches): 100%|███████████████████████████████████████████████████████████████████████████████████| 854/854 [10:03<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.21703902  0.24483639  0.84084994 ... -0.9410807   0.5486869\n",
      "  -0.8347917 ]\n",
      " [-0.9579422   0.8365362  -0.07090097 ... -1.0124918   0.7626926\n",
      "  -0.67816687]\n",
      " [-0.92578536  0.27937323  0.05952085 ... -0.7978405   0.31176674\n",
      "  -0.23223938]\n",
      " [-0.2563166   0.312091    0.12094273 ... -0.77831846  0.10287943\n",
      "  -1.0198553 ]\n",
      " [-0.6365057   0.45622563 -0.87495977 ... -0.4821485   0.8690314\n",
      "   0.52157336]]\n",
      "Embeddings shape: (54605, 256)\n",
      "Closest sentences:\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model = bert.to(device)\n",
    "    \n",
    "    batch_outputs = []\n",
    "    \n",
    "    for batch in tqdm(dataloader, desc='Getting Embeddings (batches): '):\n",
    "        \n",
    "        # Load to CUDA device for performance\n",
    "        batch.to(device)\n",
    "        \n",
    "        # Run through pre-trained BERT_Mini\n",
    "        out = bert(**batch)\n",
    "        \n",
    "        # Take last hidden state only\n",
    "        last_hidden = out.last_hidden_state\n",
    "        \n",
    "        # Obtain sentence level embedding by mean pooling\n",
    "        sentence_embeddings = torch.mean(last_hidden, dim=1)\n",
    "        batch_outputs.append(sentence_embeddings)\n",
    "\n",
    "    # combine outputs in vertical stack\n",
    "    output = torch.vstack(batch_outputs)\n",
    "    embeddings = output.cpu().numpy()\n",
    "\n",
    "print(embeddings[:5])\n",
    "print('Embeddings shape:', embeddings.shape)\n",
    "print('Closest sentences:')\n",
    "print_closest_sentences(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96e70b5-c683-4d2e-b068-a5bbad6fd8ae",
   "metadata": {},
   "source": [
    "### Last **n** layers, sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17543dc8-08f6-4fc5-bad3-e5848808d144",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model = bert.to(device)\n",
    "    \n",
    "    batch_outputs = []\n",
    "    hs = [i for i in range(-4, 0)]\n",
    "    \n",
    "    for batch in tqdm(dataloader, desc='Getting Embeddings (batches): '):\n",
    "        \n",
    "        # Load to CUDA device for performance\n",
    "        batch.to(device)\n",
    "        \n",
    "        # Run through pre-trained BERT_Mini\n",
    "        out = bert(**batch)\n",
    "        \n",
    "        # Get last n hidden layers\n",
    "        last_n_hidden = out.hidden_states[-4:]\n",
    "        \n",
    "        # stack and sum\n",
    "        hiddens = torch.stack(last_n_hidden)\n",
    "        resulting_states = torch.sum(hiddens, dim=0)\n",
    "        \n",
    "        # take the mean for combination of token level embeddings to sentence level\n",
    "        sentence_embeddings = torch.mean(resulting_states, dim=1)\n",
    "        batch_outputs.append(sentence_embeddings)\n",
    "          \n",
    "    # add everything to vstack and convert back to numpy\n",
    "    output = torch.vstack(batch_outputs)\n",
    "    embeddings = output.cpu().numpy()\n",
    "    \n",
    "# print interesting info\n",
    "print(embeddings[:5])\n",
    "print('Embeddings shape:', embeddings.shape)\n",
    "print('Closest sentences:')\n",
    "print_closest_sentences(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406161ea-cd5b-4199-8d99-be9570116305",
   "metadata": {},
   "source": [
    "### Last *n* layers, concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fedbf80-8402-4e17-839d-27d2d9b60d63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model = bert.to(device)\n",
    "    \n",
    "    batch_outputs = []\n",
    "    hs = [i for i in range(-4, 0)]\n",
    "    \n",
    "    for batch in tqdm(dataloader, desc='Getting Embeddings (batches): '):\n",
    "        \n",
    "        # Load to CUDA device for performance\n",
    "        batch.to(device)\n",
    "        \n",
    "        # Run through pre-trained BERT_Mini\n",
    "        out = bert(**batch)\n",
    "        \n",
    "        # Get last n hidden layers\n",
    "        last_n_hidden = out.hidden_states[-4:]\n",
    "        \n",
    "        # concatenate last n hidden states\n",
    "        hiddens = torch.stack(last_n_hidden)\n",
    "        resulting_states = torch.cat(last_n_hidden, dim=-1)\n",
    "        \n",
    "        # take the mean for combination of token level embeddings to sentence level\n",
    "        sentence_embeddings = torch.mean(resulting_states, dim=1)\n",
    "        batch_outputs.append(sentence_embeddings)\n",
    "          \n",
    "    # add everything to vstack and convert back to numpy\n",
    "    output = torch.vstack(batch_outputs)\n",
    "    embeddings = output.cpu().numpy()\n",
    "    \n",
    "# print interesting info\n",
    "print(embeddings[:5])\n",
    "print('Embeddings shape:', embeddings.shape)\n",
    "print('Closest sentences:')\n",
    "print_closest_sentences(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafe385c-41fc-4942-a8f0-f6255515151d",
   "metadata": {},
   "source": [
    "### SBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b612dc32-b06c-4140-ac32-251a609afc36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Well-performing SBERT model\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "# Embed sentences using the SBERT model\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "# Print interesting info\n",
    "print(embeddings[:5])\n",
    "print('Embedding shape:', embeddings.shape)\n",
    "print('Closest sentences:')\n",
    "print_closest_sentences(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82293f8-3da3-4357-8cd4-f3174fdc6f40",
   "metadata": {},
   "source": [
    "## [CLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "1a4f0276-4462-4173-942a-2462d26af5e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting Embeddings (batches): 100%|███████████████████████████████| 171/171 [02:12<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.3040098  -0.50292176  0.46082702 ... -1.324414   -0.4234199\n",
      "  -1.3706305 ]\n",
      " [-0.4365894  -0.6877635   0.46830153 ... -1.6171923   0.47544035\n",
      "  -0.8923465 ]\n",
      " [-0.31683505 -1.1239557   0.45919332 ... -1.0899997   0.05394313\n",
      "  -0.7031704 ]\n",
      " [-0.6155357  -1.1996818   0.6698872  ...  0.5729731  -0.76200986\n",
      "   0.06233907]\n",
      " [-0.4074057  -1.4478451  -0.22949722 ... -0.99145806  0.5018565\n",
      "  -0.29991972]]\n",
      "Embeddings shape: (10921, 256)\n",
      "Closest sentences:\n",
      "a building is surrounded by green trees and meadows . <-> the playground next to the street has a total of three tennis courts and an orange runway .\n",
      "in the middle of the picture is the lawn around the building . <-> the playground next to the street has a total of three tennis courts and an orange runway .\n",
      "a white plane is on the runway . <-> the playground next to the street has a total of three tennis courts and an orange runway .\n",
      "look the mountain is green . <-> the playground next to the street has a total of three tennis courts and an orange runway .\n",
      "a bridge is on a river with green water . <-> two baseball fields are located in the huage area of grassland next to road .\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model = bert.to(device)\n",
    "    \n",
    "    batch_outputs = []\n",
    "    \n",
    "    for batch in tqdm(dataloader, desc='Getting Embeddings (batches): '):\n",
    "        \n",
    "        # Load to CUDA device for performance\n",
    "        batch.to(device)\n",
    "        \n",
    "        # Run through pre-trained BERT_Mini\n",
    "        out = bert(**batch)\n",
    "        \n",
    "        sentence_embeddings = out.last_hidden_state[:, 0, :]\n",
    "        batch_outputs.append(sentence_embeddings)\n",
    "\n",
    "    # combine outputs in vertical stack\n",
    "    output = torch.vstack(batch_outputs)\n",
    "    embeddings = output.cpu().numpy()\n",
    "\n",
    "print(embeddings[:5])\n",
    "print('Embeddings shape:', embeddings.shape)\n",
    "print('Closest sentences:')\n",
    "print_closest_sentences(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d6bc20-5db1-464a-8a20-687f75192ec8",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a5f321-5497-45c5-8282-ae273a4be417",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_closest_sentences(embeddings):\n",
    "\n",
    "    cosine_similarities = cosine_similarity(embeddings, embeddings)\n",
    "    np.fill_diagonal(cosine_similarities, -np.inf)\n",
    "\n",
    "    closest_indices = np.argmax(cosine_similarities, axis=1)\n",
    "\n",
    "    biggest_closest = np.argpartition(closest_indices,-5)[-5:]\n",
    "\n",
    "    for idx in biggest_closest:\n",
    "        value = closest_indices[idx]\n",
    "        print(sentences[idx], '<->', sentences[value])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
